# Depth Cues:
**I. Monocular Static (pictorial)**
1. Linear perspective
2. Texture gradient
3. Size gradient
4. Occlusion
5. Depth of focus
6. Shape-from-shading
7. Vertical position
8. Relative size to familiar objects
9. Cast shadows
10. Depth-from-eye accommodation (this is nonpictorial)
----
**II. Monocular dynamic (moving picture)**
1. Structure-from-motion (kinetic depth, motion parallax)
---
**III. Binocular**
1. Eye convergence
2. Stereoscopic depth

## Perspective Cues
- **Parallel lines** *converge* to a point.
- objects of **known size** have a powerful role in determining the size of **unkown** one.
- Texture elements become **smaller** with distance.

## Pictures Seen from the Wrong Viewpoint
- robustness of linear perspective
- FTVR: motion parallax
> With this information,
a 3D scene can be computed and viewed so the perspective is “correct” at all
times by adjusting the viewpoint parameters in the computer graphics software
(Deering, 1992). I called this setup fish-tank virtual reality to contrast it with the
immersive virtual reality that is obtained with head-mounted displays

## Occlusion
- If one object overlaps or occludes another, it appears closer to the observer

## Shaping Models
1. Lambertian shading
2. Specular shading
3. Ambient shading
3. Cast shadows
> The kinds of complex shadows that result from multiple light
sources and radiosity modeling may be visually confusing rather than helpful.

## Cushion Maps
## Surface Texture
## Cast Shadows
- relative height of objects above a plane
- shadow motion
